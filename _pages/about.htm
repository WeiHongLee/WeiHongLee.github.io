---
permalink: /
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
---

{% include base_path %}

<!DOCTYPE html>

<html lang="en" class="UoE"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">


    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    
    <title>AboutMe</title>
    
    <!-- Bootstrap core CSS -->
    <link href="./AboutMe/bootstrap.min.css" rel="stylesheet">
    
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <link href="./AboutMe/ie10-viewport-bug-workaround.css" rel="stylesheet">
    <!-- Fontawesome -->
    <link rel="stylesheet" href="./AboutMe/font-awesome.min.css">
    
    <!-- Custom styles for this template -->
    <link href="./AboutMe/starter-template.css" rel="stylesheet">
    <!-- My own style -->
    <link href="./AboutMe/project_style.css" rel="stylesheet">
    
    <!-- Fonts -->
    <link href="./AboutMe/css" rel="stylesheet" type="text/css">
    <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
    <script async="" src="./AboutMe/analytics.js"></script><script src="./AboutMe/ie-emulation-modes-warning.js"></script>
    <!-- Google analytics snippet -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    
      ga('create', 'UA-96369953-1', 'auto');
      ga('send', 'pageview');
    </script>

<!--     <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    
      ga('create', 'UA-96369953-3', 'auto');
      ga('send', 'pageview');
    </script> -->

  </head>

  <body data-gr-c-s-loaded="true">

    <div class="container">
      <div class="row">

        <!-- <div style="text-align:justify"><h1>李伟宏 Wei-Hong Li</h1></div> -->
        <div style="text-align:justify"><h1>Biography</h1></div>
        <!-- <p>&nbsp;</p> -->
        &nbsp;
        &nbsp;
        &nbsp;
        &nbsp;
    	  <div style="text-align:center"><img class="img-responsive center-block" alt="pipeline picture" src="https://WeiHongLee.github.io/images/MyPic.png" style="width:55%"></div>
        &nbsp;     
        &nbsp;
        <!-- <p>&nbsp;</p> -->
        <div style="text-align:justify; font-size:87%"><p class="abstract text-justify">Wei-Hong Li is currently a research associate (postdoc) within <a href="http://groups.inf.ed.ac.uk/vico/">the VICO Group</a> led by <a href="http://homepages.inf.ed.ac.uk/hbilen/index.html">Hakan Bilen</a> in the School of Informatics at the University of Edinburgh. Prior to postdoc, he completed his PhD in the same group, supervised by <a href="http://homepages.inf.ed.ac.uk/hbilen/index.html">Hakan Bilen</a> and <a href="https://homepages.inf.ed.ac.uk/thospeda/">Timothy Hospedales</a>. His research interests are in computer vision and machine learning, with a focus on multi-task/domain learning and learning visual models from limited human supervision. He has been a reviewer for top-tier conferences such as CVPR, ICCV, Neurips and journals such as TPAMI et al. He was invited to give talks at VGG, Sun Yat-sen University et al. His <a href="https://groups.inf.ed.ac.uk/vico/research/MTPSL/">MTPSL</a> paper was listed in the <a href="https://twitter.com/CVPR/status/1539772091112857600">CVPR 2022 Best Paper Finalists</a>.
        </p>
        <p>
          <b>Happy to chat about any topics, in particular research in Computer Vision! Feel free to send an email.</b>
        </p>
        <p>
        Before Edinburgh, he did his master and bachelor at Sun Yat-sen University, working with <a href="http://www.isee-ai.cn/~zhwshi/index.html">Wei-Shi Zheng</a> who thankfully introduced him to computer vision. During the master program, he was lucky to visit Queen Mary University of London to work with <a href="http://www.eecs.qmul.ac.uk/~sgg/">Shaogang Gong</a>.
<!-- 
          My research focuses on computer vision and machine learning. Specifically, I am currently working on designing machine learning systems that learn with less supervision and systems that learn to perform multiple tasks within a single model. -->
        </p>
          <b>I'm on the job market. Feel free to contact me.</b>
        <p>
        </p>
        <!-- <p>
          <font color="D50032">
            I am looking for job starting earlier next year (2024), let me know if you have opening positions!
          </font>
        </p> -->
        </div>  
        &nbsp; 
        <!-- Before Edinburgh, I have completed my master and bachelor supervised by Prof. <a href="http://www.isee-ai.cn/~zhwshi/index.html">Wei-Shi Zheng</a> in the iSEE group at Sun Yat-sen University where I was working on Object Tracking, Person Re-identification and Important People Detection. It is a great time to work with Prof. Wei-Shi Zheng who thankfully introduced me to computer vision. During the master program, I was lucky to have a visiting study in the Vision Group at Queen Mary University of London where I focused on video search with Prof. <a href="http://www.eecs.qmul.ac.uk/~sgg/">Shaogang Gong</a>. -->
        <div style="text-align:left">
          <small>
            <p class="pointers_sub">

            <b><font color="D50032">News</font></b> (July 2023): Our <a href="https://arxiv.org/abs/2204.02744">Universal Representations</a> paper is accepted by IJCV. Congrats to Xialei and Hakan!<br>

            <b><font color="D50032">News</font></b> (July 2023): Giving a talk about our <a href="https://groups.inf.ed.ac.uk/vico/research/MTPSL/">MTPSL paper</a> at the IPAB Workshop.<br>

            <b><font color="D50032">News</font></b> (June 2023): Presenting our <a href="https://groups.inf.ed.ac.uk/vico/research/TSA/">TSA paper</a> at the <a href="https://www.bayeswatch.com/affordable_ml/">Affordable Machine Learning Workshop</a>.<br>

            <b><font color="D50032">News</font></b> (March 2023): Giving an invited talk (Learning universal representations across tasks and domains) at the Sun Yat-sen University, China.<br>

            <b><font color="D50032">News</font></b> (December 2022): My PhD thesis titled "<a href="https://era.ed.ac.uk/handle/1842/39625">Learning universal representations across tasks and domains</a>" has been released!<br>

            <b><font color="D50032">News</font></b> (September 2022): We are organizing the <a href="https://sites.google.com/view/universalrepresentations">Universal Representations for Computer Vision Workshop</a> at BMVC 2022. We invite submissions of regular and short papers. See <a href="https://sites.google.com/view/universalrepresentations/call-for-papers">Call for Papers</a> for more details!<br>

            <b><font color="D50032">News</font></b> (September 2022): One paper accepted by TMM. Congrats to Yu-Kun, Fa-Ting, and Wei-Shi!<br>

            <b><font color="D50032">News</font></b> (August 2022): I am excited to start my postdoc at the University of Edinburgh, working with Hakan Bilen!<br>

            <b><font color="D50032">News</font></b> (August 2022): I have passed my PhD viva with my thesis "Learning Universal Representations Across Tasks and Domains". Great thanks to examiners <a href="https://vilab.epfl.ch/zamir/">Amir Zamir</a> and <a href="https://laurasevilla.me">Laura Sevilla</a> and my supervisor Hakan Bilen!<br>

            <b><font color="D50032">News</font></b> (July 2022): We've released the <a href="https://github.com/VICO-UoE/UniversalRepresentations">code</a> of our <a href="https://arxiv.org/abs/2204.02744">Universal Representation Learning paper</a>.<br>

            <b><font color="D50032">News</font></b> (June 2022): We've released the <a href="https://github.com/VICO-UoE/MTPSL">code</a> of our "<a href="https://groups.inf.ed.ac.uk/vico/research/MTPSL/">Learning Multiple Dense Prediction Tasks from Partially Annotated Data</a>" paper (CVPR 2022).<br>

            <b><font color="D50032">News</font></b> (June 2022): Our "<a href="https://groups.inf.ed.ac.uk/vico/research/MTPSL/">Learning Multiple Dense Prediction Tasks from Partially Annotated Data</a>" paper is listed in the CVPR 2022 <b><a style="color:DarkRed" href="https://twitter.com/CVPR/status/1539772091112857600">Best Paper Finalists</a></b>.<br>

            <b><font color="D50032">News</font></b> (April 2022): We've released a preprint of our work '<a href="https://arxiv.org/pdf/2204.02744.pdf">Universal Representations: A Unified Look at Multiple Task and Domain Learning</a>'.<br>

            <b><font color="D50032">News</font></b> (March 2022): We've released the <a href="https://github.com/VICO-UoE/URL">code</a> of our <a href="https://groups.inf.ed.ac.uk/vico/research/TSA/">TSA paper</a> (CVPR 2022).<br>

            <b><font color="D50032">News</font></b> (March 2022): Two papers accepted to CVPR 2022. Congrats to Xialei and Hakan!<br>

            <b><font color="D50032">News</font></b> (February 2022): Giving an invited presentation (<a href="https://github.com/VICO-UoE/URL">Universal Representation Learning and Task-specific Adaptation for Few-shot Learning</a>) in VGG, University of Oxford.<br>

            <b><font color="D50032">News</font></b> (February 2022): I maintain an up-to-date list of works on Multi-task Learning <a href="https://github.com/WeiHongLee/Awesome-Multi-Task-Learning">here</a>.<br>

            <b><font color="D50032">News</font></b> (December 2021): We've released a preprint of our work on <a href="https://arxiv.org/pdf/2111.14893.pdf">Multi-task Partially Supervised Learning</a>.<br>

            <b><font color="D50032">News</font></b> (October 2021): We've released the <a href="https://github.com/VICO-UoE/URL">code</a> of our <a href="https://groups.inf.ed.ac.uk/vico/research/URL/">URL paper</a> (ICCV 2021).<br>

            <b><font color="D50032">News</font></b> (July 2021): <a href="https://weihonglee.github.io/Projects/URL/URL.htm">One paper</a> to appear at ICCV 2021. Congrats to Xialei and Hakan!<br>

            <b><font color="D50032">News</font></b> (July 2021): We've released a preprint of our recent work on <a href="https://weihonglee.github.io/Projects/RA/RA.htm">'Cross-domain Few-shot Learning with Task-specific Adapters'</a>.<br>

            <b><font color="D50032">News</font></b> (April 2021): We've released the <a href="https://github.com/harlanhong/CVPR2020-Semi-Point">code</a> of <a href="https://weihonglee.github.io/Projects/Learning-to-Rank/Learning-to-Rank.htm">semi-supervised important people detection (CVPR 2020)</a>.<br>

            <b><font color="D50032">News</font></b> (March 2021): We've released a preprint of our recent work on <a href="https://weihonglee.github.io/Projects/URL/URL.htm">'Universal Representation Learning from Multiple Domains for Few-shot Classification'</a>.<br>

            <b><font color="D50032">News</font></b> (December 2020): <a href="https://github.com/Huangxt57/MINI-Net">Code</a> for our "MINI-Net: Multiple Instance Ranking Network for Video Highlight Detection" paper is available.<br>

            <b><font color="D50032">News</font></b> (September 2020): <a href="https://WeiHongLee.github.io/Projects/KD-MTL/KD-MTL.htm">Code</a> for our "Knowledge Distillation for Multi-task Learning" paper is now available.<br>

            <b><font color="D50032">News</font></b> (August 2020): Attending and presenting our work at ECCV 2020.<br>

            <b><font color="D50032">News</font></b> (July 2020): <a href="https://arxiv.org/pdf/2007.09833.pdf">One paper</a> to appear at ECCV 2020 and <a href="https://WeiHongLee.github.io/Projects/KD-MTL/KD-MTL.htm">one</a> at the IPCV Workshop.<br>

            <b><font color="D50032">News</font></b> (June 2020): We've released the <a href="https://WeiHongLee.github.io/Projects/Learning-to-Rank/Learning-to-Rank.htm">EMS and ENCAA datasets</a>.<br>

            <b><font color="D50032">News</font></b> (February 2020): One paper to appear at CVPR 2020. The <a href="https://WeiHongLee.github.io/Projects/Learning-to-Rank/Learning-to-Rank.htm">paper and poster</a> are now online.<br>

            <b><font color="D50032">News</font></b> (January 2020): Attending the Informatics Workshop (Meta-learning) at University of Edinburgh.<br>

            <b><font color="D50032">News</font></b> (December 2019): The paper and code of our recent work on semi-supervised learning are now available at <a href="https://WeiHongLee.github.io/Projects/Learning-to-impute/Learning-to-impute.htm">our project page</a>.<br>

            <b><font color="D50032">News</font></b> (December 2019): Attending the Huawei Research Workshop in Shanghai.<br>

            <b><font color="D50032">News</font></b> (November 2019): Attending the Amazon Research Day and presenting my recent work on semi-supervised learning.<br>

            <b><font color="D50032">News</font></b> (September 2019): Pass my first annual review.<br>

            <b><font color="D50032">News</font></b> (June 2019): Attending CVPR 2019 in Long Beach, USA, for presenting my recent paper on <a href="https://weihonglee.github.io/Projects/POINT/POINT.htm">important people detection</a>.<br>

            <b><font color="D50032">News</font></b> (April 2019): The Paper, Code and Supplementary Material of our CVPR 2019 paper are available at <a href="https://weihonglee.github.io/Projects/POINT/POINT.htm">our project page</a>.<br>		
            <b><font color="D50032">News</font></b> (March 2019): The paper <a href="https://weihonglee.github.io/Projects/SoDA/SoDA.htm"><I>One-pass Person Re-identiﬁcation by Sketched Online Discriminant Analysis</I></a> is accepted to be published in Pattern Recognition (PR). Congrats to Zhuowei Zhong and Wei-Shi Zheng.<br>
            <b><font color="D50032">News</font></b> (February 2019): The paper <I><a href="https://arxiv.org/pdf/1904.03632.pdf">Learning to Learn Relation for Important People Detection in Still Images</a></I> is accepted by CVPR 2019. Congrats to Fa-Ting Hong and Wei-Shi Zheng.<br>	

            <b><font color="D50032">News</font></b> (February 2019): Our <a href="http://groups.inf.ed.ac.uk/vico/">group page</a> is now available.<br>

            <b><font color="D50032">News</font></b> (October 2018): Two important people image <a href="https://weihonglee.github.io/Projects/PersonRank.htm">datasets</a> are available!<br>
            <b><font color="D50032">News</font></b> (September 2018): I am excited to start my PhD study with <a href="http://homepages.inf.ed.ac.uk/hbilen/index.html">Prof. Hakan Bilen</a>.<br>
            <b><font color="D50032">News</font></b> (January 2018): The paper <a href="https://arxiv.org/abs/1711.01984"><I>PersonRank: Detecting Important People in Images</I></a> is accepted by the FG 2018 as an oral paper.<br>
            <b><font color="D50032">News</font></b> (December 2017): The paper <a href="https://arxiv.org/abs/1711.03368"><I>One-pass Person Re-identiﬁcation by Sketched Online Discriminant Analysis</I></a> is available on arXiv and the project page can be found <a href="https://weihonglee.github.io/Projects/SoDA/SoDA.htm">here</a>.<br>
            <b><font color="D50032">News</font></b> (September 2017): The paper <a href="https://weihonglee.github.io/papers/Correlation_based_Identity_Filter-_An_Efﬁcient_Framework_For_Person_Search.pdf"><I>Correlation based Identity Filter: An Efficient Framework For Person Search</I></a> is accepted by <a href="http://www.icig2017.org">ICIG 2017</a> and is awarded <B style="color:DarkRed"> <a style="color:DarkRed" href="http://www.cast.org.cn/n200720/n203107/n203243/c57682793/content.html">The Best Paper Award</a></B>.
            </p>
          </small>
<!--           <p class="pointers" style="text-align:left">&#9656 <a href="./stuff/Staple_website_results.zip">Results (coming soon) <i class="fa fa-file-zip-o"> </i></a><small></p>
 -->    </div>


<!-- <span id="buffer-extension-hover-button" style="display: none;position: absolute;z-index: 8675309;width: 100px;height: 25px;background-image: url(chrome-extension://noojglkidnpfjbincgijbaiedldjfbhh/data/shared/img/buffer-hover-icon@1x.png);background-size: 100px 25px;opacity: 0.9;cursor: pointer;"></span></body></html> -->
</small></small></body></html>
