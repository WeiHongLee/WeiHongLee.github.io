---
title: "Publications"
permalink: /publications/
author_profile: true
redirect_from:
  - /md/
  - /markdown.html
---


<!DOCTYPE html>

<html lang="en" class="SYSU"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

 

    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    
    <title>Publications</title>
    
    <!-- Bootstrap core CSS -->
    <link href="./Basic/bootstrap.min.css" rel="stylesheet">
    
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <link href="./Basic/ie10-viewport-bug-workaround.css" rel="stylesheet">
    <!-- Fontawesome -->
    <link rel="stylesheet" href="./Basic/font-awesome.min.css">
    
    <!-- Custom styles for this template -->
    <link href="./Basic/starter-template.css" rel="stylesheet">
    <!-- My own style -->
    <link href="./Basic/project_style.css" rel="stylesheet">
    
    <!-- Fonts -->
    <link href="./Basic/css" rel="stylesheet" type="text/css">
    <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
    <script async="" src="./Basic/analytics.js"></script><script src="./Basic/ie-emulation-modes-warning.js"></script>
    <!-- Google analytics snippet -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    
      ga('create', 'UA-96369953-1', 'auto');
      ga('send', 'pageview');
    </script>

<!--     <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    
      ga('create', 'UA-96369953-3', 'auto');
      ga('send', 'pageview');
    </script> -->

  </head>

  <body data-gr-c-s-loaded="true">

    <div class="container">
      <div class="row">
        <!-- <div style="text-align:left"><B><B><h1>Publication List</B></B></strong></div> -->
        &nbsp;
        &nbsp;
        &nbsp;      
        &nbsp; 
        <div>

        <p class="pointers_sub">
        <small><B>Universal Representations: A Unified Look at Multiple Task and Domain Learning</B></small>.<br>
        <small><B><I>Wei-Hong Li</I></B>, Xialei Liu, Hakan Bilen</small>.<br>
        <small style="color:DarkRed">Preprint</small>, <small>2022</small>. <small>[<a href="https://arxiv.org/pdf/2204.02744.pdf">arXiv</a>] [<a href="https://github.com/VICO-UoE/UniversalRepresentations">Code</a>]</small>
        </p>

        <p class="pointers_sub">
        <small><B>Learning Multiple Dense Prediction Tasks from Partially Annotated Data</B></small>.<br>
        <small><B><I>Wei-Hong Li</I></B>, Xialei Liu, Hakan Bilen</small>.<br>
        <small style="color:DarkRed">International Conference on Computer Vision and Pattern Recognition</small> <small>(</small><small style="color:DarkRed">CVPR</small><small>)</small>, <small style="color:DarkRed"><b>oral</b></small>, <small>2022</small>. <small>[<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Learning_Multiple_Dense_Prediction_Tasks_From_Partially_Annotated_Data_CVPR_2022_paper.pdf">CVF</a>] [<a href="https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Learning_Multiple_Dense_CVPR_2022_supplemental.pdf">supp</a>] [<a href="https://arxiv.org/pdf/2111.14893.pdf">arXiv</a>] [<a href="https://github.com/VICO-UoE/MTPSL">Code</a>] [<a href="https://groups.inf.ed.ac.uk/vico/research/MTPSL/">Project</a>]</small>
        </p>

        <p class="pointers_sub">
        <small><B>Cross-domain Few-shot Learning with Task-specific Adapters</B></small>.<br>
        <small><B><I>Wei-Hong Li</I></B>, Xialei Liu, Hakan Bilen</small>.<br>
        <small style="color:DarkRed">International Conference on Computer Vision and Pattern Recognition</small> <small>(</small><small style="color:DarkRed">CVPR</small><small>)</small>, <small>2022</small>. <small>[<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Cross-Domain_Few-Shot_Learning_With_Task-Specific_Adapters_CVPR_2022_paper.pdf">CVF</a>] [<a href="https://openaccess.thecvf.com/content/CVPR2022/supplemental/Li_Cross-Domain_Few-Shot_Learning_CVPR_2022_supplemental.pdf">supp</a>] [<a href="https://arxiv.org/pdf/2107.00358.pdf">arXiv</a>] [<a href="https://github.com/VICO-UoE/URL">Code</a>] [<a href="https://groups.inf.ed.ac.uk/vico/research/TSA/">Project</a>]</small>
        </p>

        <p class="pointers_sub">
        <small><B>Universal Representation Learning from Multiple Domains for Few-shot Classification</B></small>.<br>
        <small><B><I>Wei-Hong Li</I></B>, Xialei Liu, Hakan Bilen</small>.<br>
        <small style="color:DarkRed">International Conference on Computer Vision</small> <small>(</small><small style="color:DarkRed">ICCV</small><small>)</small>, <small>2021</small>. <small>[<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Li_Universal_Representation_Learning_From_Multiple_Domains_for_Few-Shot_Classification_ICCV_2021_paper.pdf">CVF</a>] [<a href="https://openaccess.thecvf.com/content/ICCV2021/supplemental/Li_Universal_Representation_Learning_ICCV_2021_supplemental.pdf">supp</a>] [<a href="https://arxiv.org/pdf/2103.13841.pdf">arXiv</a>] [<a href="https://github.com/VICO-UoE/URL">Code</a>] [<a href="https://groups.inf.ed.ac.uk/vico/research/URL/">Project</a>]</small>
        </p>

        <p class="pointers_sub">
        <small><B>Knowledge Distillation for Multi-task Learning</B></small>.<br>
        <small><B><I>Wei-Hong Li</I></B>, Hakan Bilen</small>.<br>
        <small style="color:DarkRed">European Conference on Computer Vision Workshop on Imbalance Problems in Computer Vision</small> <small>(</small><small style="color:DarkRed">ECCVW</small><small>)</small>, <small>2020</small>. <small>[<a href="https://arxiv.org/pdf/2007.06889.pdf">arXiv</a>] [<a href="https://github.com/VICO-UoE/KD4MTL">Code</a>] [<a href="https://www.youtube.com/watch?v=ckcFSi35Wuk&feature=youtu.be">talk</a>] [<a href="https://WeiHongLee.github.io/Projects/KD-MTL/KD-MTL.htm">Project</a>]</small>
        </p>

        <p class="pointers_sub">
        <small><B>MINI-Net: Multiple Instance Ranking Network for Video Highlight Detection</B></small>.<br>
        <small>Fa-Ting Hong, Xuanteng Huang, <B><I>Wei-Hong Li</I></B>, Wei-Shi Zheng</small>.<br>
        <small style="color:DarkRed">European Conference on Computer Vision</small> <small>(</small><small style="color:DarkRed">ECCV</small><small>)</small>, <small>2020</small>. <small>[<a href="https://arxiv.org/pdf/2007.09833.pdf">arXiv</a>] [<a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123580341.pdf">ECVA</a>]</small> <small>[<a href="https://github.com/Huangxt57/MINI-Net">Code</a>]</small> <small>[<a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123580341-supp.pdf">supp</a>]</small>
        </p>

        <p class="pointers_sub">
        <small><B>Learning to Detect Important People in Unlabelled Images for Semi-supervised Important People Detection</B></small>.<br>
        <small>Fa-Ting Hong*, <B><I>Wei-Hong Li</I></B>*, Wei-Shi Zheng</small>.<br>
        <small style="color:DarkRed">International Conference on Computer Vision and Pattern Recognition</small> <small>(</small><small style="color:DarkRed">CVPR</small><small>)</small>, <small>2020</small>. <small>[<a href="https://arxiv.org/abs/2004.07568">arXiv</a>] [<a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Hong_Learning_to_Detect_Important_People_in_Unlabelled_Images_for_Semi-Supervised_CVPR_2020_paper.html">CVF</a>] [<a href="https://WeiHongLee.github.io/Projects/Learning-to-Rank/Learning-to-Rank.htm">Project</a>]</small> <small>[<a href="https://mail2sysueducn-my.sharepoint.com/personal/hongft3_mail2_sysu_edu_cn/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fhongft3%5Fmail2%5Fsysu%5Fedu%5Fcn%2FDocuments%2Frelease%2Ddataset%2FEMS%2Ezip&parent=%2Fpersonal%2Fhongft3%5Fmail2%5Fsysu%5Fedu%5Fcn%2FDocuments%2Frelease%2Ddataset">EMS Dataset</a>]</small> <small>[<a href="https://mail2sysueducn-my.sharepoint.com/personal/hongft3_mail2_sysu_edu_cn/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fhongft3%5Fmail2%5Fsysu%5Fedu%5Fcn%2FDocuments%2Frelease%2Ddataset%2FENCAA%2Ezip&parent=%2Fpersonal%2Fhongft3%5Fmail2%5Fsysu%5Fedu%5Fcn%2FDocuments%2Frelease%2Ddataset">ENCAA Dataset</a>]</small>
        </p>

        <p class="pointers_sub">
        <small><B>Learning to Impute: A General Framework for Semi-supervised Learning</B></small>.<br>
        <small><B><I>Wei-Hong Li</I></B>, Chuan-Sheng Foo, Hakan Bilen</small>.<br>
        <small style="color:DarkRed">Preprint</small>, <small>2019</small>. <small>[<a href="https://arxiv.org/pdf/1912.10364.pdf">arXiv</a>] [<a href="https://github.com/VICO-UoE/L2I">Code</a>] [<a href="https://WeiHongLee.github.io/Projects/Learning-to-impute/Learning-to-impute.htm">Project</a>]</small>
        </p>

        <p class="pointers_sub">
        <small><B>One-pass Person Re-identiÔ¨Åcation by Sketched Online Discriminant Analysis</B></small>.<br>
        <small><B><I>Wei-Hong Li</I></B>, Zhuowei Zhong, Wei-Shi Zheng</small>.<br>
        <small style="color:DarkRed">Pattern Recognition</small> <small>(</small><small style="color:DarkRed">PR</small><small>)</small>, <small>2019</small>. <small>[<a href="https://arxiv.org/abs/1711.03368">PDF</a>] [<a href="https://WeiHongLee.github.io/Projects/SoDA/SoDA.htm">Project</a>]</small>
        </p>
          
        <p class="pointers_sub">
        <small><B>Learning to Learn Relation for Important People Detection in Still Images</B></small>.<br>
        <small><B><I>Wei-Hong Li</I></B>*, Fa-Ting Hong*, Wei-Shi Zheng</small>.<br>
        <small style="color:DarkRed">International Conference on Computer Vision and Pattern Recognition</small> <small>(</small><small style="color:DarkRed">CVPR</small><small>)</small>, <small>2019</small>. <small>[<a href="https://arxiv.org/pdf/1904.03632.pdf">arXiv</a>] [<a href="http://openaccess.thecvf.com/content_CVPR_2019/html/Li_Learning_to_Learn_Relation_for_Important_People_Detection_in_Still_CVPR_2019_paper.html">CVF</a>] [<a href="https://WeiHongLee.github.io/papers/2305-supp.pdf">supp</a>] [<a href="https://WeiHongLee.github.io/Projects/POINT/POINT.htm">Project</a>]</small>
        </p>

        <p class="pointers_sub">
        <small><B>PersonRank: Detecting Important People in Images</B></small>.<br>
        <small><B><I>Wei-Hong Li</I></B>, Benchao Li, Wei-Shi Zheng</small>.<br>
        <small style="color:DarkRed">International Conference on Automatic Face and Gesture Recognition </small><small>(</small><small style="color:DarkRed">FG</small><small>)</small>, <small style="color:DarkRed"><b>oral</b></small>, <small>2018</small>. <small>[<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8373835">PDF</a>] [<a href="https://WeiHongLee.github.io/Projects/PersonRank.htm">Project</a>]</small> <small>[<a href="https://uoe-my.sharepoint.com/personal/s1798461_ed_ac_uk/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fs1798461%5Fed%5Fac%5Fuk%2FDocuments%2Fdataset%2FMS%20DataSet%2Ezip&parent=%2Fpersonal%2Fs1798461%5Fed%5Fac%5Fuk%2FDocuments%2Fdataset">MS Dataset</a>]</small> <small>[<a href="https://uoe-my.sharepoint.com/personal/s1798461_ed_ac_uk/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fs1798461%5Fed%5Fac%5Fuk%2FDocuments%2Fdataset%2FNCAA%20Dataset%2Ezip&parent=%2Fpersonal%2Fs1798461%5Fed%5Fac%5Fuk%2FDocuments%2Fdataset">NCAA Dataset</a>]</small> 
        </p>

        <p class="pointers_sub">
        <small><B>Correlation based Identity Filter: An Efficient Framework For Person Search</B></small>.<br>
        <small><B><I>Wei-Hong Li</I></B>, Yafang Mao, Ancong Wu, Wei-Shi Zheng</small>.<br>
        <small style="color:DarkRed">International Conference on Image and Graphics</small> <small>(</small><small style="color:DarkRed">ICIG</small><small>)</small>, <small style="color:DarkRed"><b>oral</b></small>, <small><b><a style="color:DarkRed" href="http://www.cast.org.cn/n200720/n203107/n203243/c57682793/content.html">Best Paper Award</a></b></small>, <small>2017</small>. <small>[<a href="https://link.springer.com/chapter/10.1007/978-3-319-71607-7_22">PDF</a>]</small>
        </p>

        <p class="pointers_sub" style="text-align:left">
        <small><B>Sketch metric learning</B></small>.<br>
        <small>Yuting Mai, <B><I>Wei-Hong Li</I></B>, Yongyi Tang, Xixi Bi, Wei-Shi Zheng</small>.<br>
        <small style="color:DarkRed">International Joint Conference on Neural Networks</small> <small>(</small><small style="color:DarkRed">IJCNN</small><small>)</small>, <small>2016</small>. <small>[<a href="https://WeiHongLee.github.io/papers/Sketch_Metric_Learning.pdf">PDF</a>]</small>
        </p>

        <p class="pointers_sub">
        <small><B>Towards Photo-Realistic Visible Watermark Removal with Conditional Generative Adversarial Networks</B></small>.<br>
        <small>Xiang Li, Chan Lu, Danni Cheng, <B><I>Wei-Hong Li</I></B>, Mei Cao, Bo Liu, Jiechao Ma, Wei-Shi Zheng</small>.<br>
        <small style="color:DarkRed">International Conference on Image and Graphics</small> <small>(</small><small style="color:DarkRed">ICIG</small><small>)</small>, <small>2019</small>. <small>[<a href="https://arxiv.org/pdf/1905.12845.pdf">PDF</a>]</small>
        </p>
          
        <p class="pointers_sub">
        <small><B>Large-Scale Visible Watermark Detection and Removal with Deep Convolutional Networks</B></small>.<br>
        <small>Danni Cheng, Xiang Li, <B><I>Wei-Hong Li</I></B>, Chan Lu, Fake Li, Hua Zhao, Wei-Shi Zheng</small>.<br>
        <small style="color:DarkRed">Chinese Conference on Pattern Recognition and Computer Vision</small><small> (</small><small style="color:DarkRed">PRCV</small><small>)</small>, <small style="color:DarkRed"><b>oral</b></small>, <small>2018</small>. <small>[<a href="https://link.springer.com/content/pdf/10.1007%2F978-3-030-03338-5_3.pdf">PDF</a>]</small> <small>[<a href="https://pan.baidu.com/s/1c3MuJ90jVcKJm2Gp-wwzNQ#list/path=%2F">Dataset (baidu)</a>]</small> <small>[<a href="https://uoe-my.sharepoint.com/:f:/g/personal/s1798461_ed_ac_uk/Er63ULEdBlhLt7fxxQuXPwEBVC-JSZUqvgRyAFMqvhsIrg?e=zXGPBd">Dataset (onedrive)</a>]</small>
        </p>
          
        <p class="pointers_sub" style="text-align:left">
        <small><B>A Delaunay-Based Temporal Coding Model for Micro-expression Recognition</B>.<br>
        Zhaoyu Lu and Ziqi Luo and Huicheng Zheng and Jikai Chen and <B><I>Wei-Hong Li</I></B>.</small><br>
        <small style="color:DarkRed">Asian Conference on Computer Vision</small> <small>(</small><small style="color:DarkRed">ACCVW</small><small>)</small>, <small>2014. [<a href="https://WeiHongLee.github.io/papers/A_Delaunay-Based_Temporal_Coding_Model_for_Micro-expression_Recognition.pdf">PDF</a>]</small>
        </p>

        </div>

<!-- <span id="buffer-extension-hover-button" style="display: none;position: absolute;z-index: 8675309;width: 100px;height: 25px;background-image: url(chrome-extension://noojglkidnpfjbincgijbaiedldjfbhh/data/shared/img/buffer-hover-icon@1x.png);background-size: 100px 25px;opacity: 0.9;cursor: pointer;"></span></body></html> -->
</small></small></body></html>
